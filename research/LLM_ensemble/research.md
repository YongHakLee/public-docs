# LLM ENSEMBLE RESEARCH

## Overview

1. 추론 전 단계: "적재적소에 배정하기" (Routing & Cascading)
2. 추론 후 단계: "다 같이 풀고 합치기" (Aggregation & MoA)
3. 상호 작용 단계: "토론하며 답 찾기" (Multi-Agent Debate)

## 1. 추론 전 단계: "적재적소에 배정하기" (Routing & Cascading)

### 1.1 기본 개념 및 정의

입력의 난이도나 특성에 맞춰 동적으로 모델을 선택하거나 순차적으로 호출하는 기술

### 1.2 상세 메커니즘: Cascading

모델을 비용이 낮은 순서대로 직렬(Sequential) 배치하여 처리하는 방식 <br>

1. 초기 추론: 입력 쿼리를 가장 작은 모델(예: 7B 파라미터 모델)에 전달
2. 응답 평가 (Scoring): 모델이 생성한 답변의 품질을 실시간으로 평가
3. 조건부 업그레이드: 평가 점수가 사전 정의된 임계값 이하인 경우, 더 큰 모델(예: 13B, 70B 파라미터 모델)로 쿼리를 전달하여 재추론

### 1.3 상세 메커니즘: Routing

입력을 처리하기 전에, 별도의 라우터(Router) 모델이 어떤 모델이 이 쿼리를 처리해야 할지 결정하여 직접 배정하는 방식

1. 입력 분석: 사용자의 쿼리가 들어오면 '라우터 모델'이 이를 분석
2. 승률 예측 (Win-rate Prediction): 라우터는 "이 쿼리를 모델 A와 모델 B가 각각 처리했을 때, 누가 더 나은 답변을 낼 것인가"를 예측
3. 경로 선택: 예측 결과에 따라 가장 적합한 모델에 쿼리를 전달하여 추론 수행

## 2. 추론 후 단계: "다 같이 풀고 합치기" (Aggregation & MoA)

### 2.1 기본 개념 및 정의

여러 모델이 생성한 결과물을 사후적으로 결합하여 단일 모델보다 우수한 성능을 도출하는 앙상블 기법

### 2.2 상세 메커니즘: 선택 기반 접근 (Selection & Ranking)

여러 모델이 각자 답변을 생성한 뒤, 별도의 알고리즘이나 모델이 "가장 정답에 가까운 것"을 하나 골라내는 방식 <br>

1. 다수결 투표 (Majority Voting / Self-Consistency)
2. 랭킹 및 검증 (Ranking & Verification)

### 2.3 상세 메커니즘: 생성 기반 접근 (Generation & Fusion)

단순히 하나를 고르는 것을 넘어, 여러 답변의 장점만을 융합(Fusion)하여 새로운 답변을 재생성하는 방식

#### A. Mixture of Answers (MoA)

- 계층적 구조 (Layered Architecture):
  - 1단계 (Proposers): 서로 다른 강점을 가진 여러 LLM(예: Qwen, Llama, Mistral 등)이 사용자의 질문에 대해 각자 초안을 작성
  - 2단계 (Aggregators): 상위 성능의 LLM이 1단계에서 생성된 모든 답변들을 '문맥(Context)'으로 입력받음
  - 3단계 (Synthesis): Aggregator 모델은 각 초안의 오류는 버리고, 유용한 정보와 통찰만을 결합하여 최종 답변을 생성

#### B. 프롬프트 기반 융합 (Prompt-based Fusion)

Aggregator 모델에게 명시적인 프롬프트를 주어 융합을 유도하는 방식 <br>

- 프롬프트 예시: "다음은 동일한 질문에 대한 3가지 모델의 답변이다. 답변 A의 논리적 구조와 답변 B의 창의적인 표현을 결합하고, 답변 C의 오류를 수정하여 완벽한 하나의 답변을 작성하라."

### 2.3 상세 메커니즘: 토큰 레벨 융합 (Token-level Fusion)

텍스트가 완성된 후 합치는 것이 아니라, 생성 과정(Decoding) 실시간으로 확률을 합치는 고난도 기술 <br>

- 작동 원리: 여러 모델이 다음 단어(Token)를 예측할 때 내놓는 확률 분포(Logits)를 가중 평균(Weighted Average)
- 제약 사항: 모든 모델의 토크나이저(Tokenizer)와 어휘 사전(Vocabulary)이 동일하거나, 매핑이 가능해야 함

## 3. 상호 작용 단계: "토론하며 답 찾기" (Multi-Agent Debate)

### 3.1 기본 개념 및 정의

여러 LLM 에이전트가 마치 사람들이 회의를 하듯 서로의 의견을 교환하고, 비판(Critique)하고, 수정(Refine)하는 과정을 통해 정답에 도달하는 방식

### 3.2 기본 작동 메커니즘

토론 기반 앙상블은 일반적으로 **[제안 → 비판 → 수정 → 합의]** 의 4단계 루프(Loop)로 진행

1. 초기 제안 (Initial Proposal):
   - 에이전트 A, B, C가 주어진 질문에 대해 각자의 첫 번째 답변을 생성함
2. 순환 비판 (Round-robin Critique):
   - 에이전트 A는 B와 C의 답변을 읽고 논리적 오류나 틀린 사실을 지적함
   - 에이전트 B도 A와 C의 답변을 비판함
3. 답변 수정 (Revision):
   - 각 에이전트는 동료들의 비판을 수용하여 자신의 답변을 수정함("아, 내가 계산 실수를 했네. 다시 풀면 42야.")
4. 수렴 및 합의 (Convergence & Consensus):
   - 이 과정을 몇 번(Round) 반복하면, 에이전트들의 답변이 하나로 비슷해짐
   - 모든 에이전트가 "더 이상 수정할 게 없다"고 동의하거나, 정해진 횟수가 끝나면 최종 답을 도출함

### 3.3 주요 토론 구조 (Architecture Types)

1. 역할 기반 토론 (Role-Playing Debate)
   - 각 에이전트에게 특정 역할(Role)을 부여하여 토론을 진행하는 방식
   - 예: 에이전트 A는 '전문가', B는 '초보자', C는 '비판가' 역할을 맡아 서로 다른 관점에서 답변을 제시하고 토론
2. 에이전트끼리만 두면 토론이 산으로 가거나 무한 루프에 빠질 수 있습니다. 이를 통제하는 '판사(Judge)' 모델을 둠
